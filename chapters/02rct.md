---
title: 'Week 2: Randomized studies of interventions'
description:
  'The essential elements, advantages and disadvantages of randomized studies of interventions will be discussed. We will cover the biases that threaten the internal validity of randomized controlled trial (RCTs). You will learn to understand and apply criteria for assessing the quality of evidence from randomized studies of interventions using the GRADE framework.'
prev: /01gt
next: null
type: chapter
id: 3
---


<exercise id="1" title="Introduction">

You will recall from NUR1027 that quantitative studies involving *manipulation* of conditions for groups of participants included in the study can broadly be categorized as **interventional** studies. Interventional studies can be further categorized as either randomized or non-randomized. 

<img src="/interventional-studies.png">

This chapter will focus on **randomized** studies of interventions. But first, I want to take a step back and put what we are going to learn into the bigger picture. In this course we are working towards developing your ability to identify clinical questions that are important to you and your team's practice and being able to use evidence to inform your decision-making regarding those questions. In other words, as 'health systems leaders and administrators' we want you to be able to make evidence-informed 'recommendations' for practice. To assist the formation of such recommendations, the best framework for you to use is known as GRADE. The GRADE framework stands for 'Grading of Recommendations Assessment, Developed and Evaluation'. I introduced this framework to you briefly in the first week of NUR1027, but now, as we start to delve deeper into some important types of research designs, it is important to look into this framework in more detail. At it's core, GRADE provides a way for us to first assess the quality of evidence, and then, based on this quality assessment, provide **recommendations** for practice that are classified according to the continuum displayed in the image below.

<a href="https://www-sciencedirect-com.myaccess.library.utoronto.ca/science/article/pii/S0895435612001382">
<img src="/strength.jpg">
</a>
<sub>GRADE guidelines: 14. Going from evidence to recommendations: the significance and presentation of recommendations</sub>
<br><br>

One really big advantage of the GRADE framework is that it moves us away from thinking about 'hierarchies' of evidence without consideration for quality. Below is the summary of GRADE I provided in NUR1027 for you to review. So what I want you to keep in mind as we move through the course this semester, is: 

<qu>What is the **strength** of the recommendation for practice I can provide either for or against this intervention, considering the quality of evidence at hand?</qu>


<div align="center" >

<img src="http://prehospitalresearch.eu/wp-content/uploads/2014/11/logo.gif"/>



</div>
<div align="center" >

**The GRADE approach involves rating the quality of evidence for each outcome along a continuum of very low, low, moderate or high quality.**

</div>

<table class="ic-Table ic-Table--hover-row">
<thead>
<tr>
<th>Evidence Rating</th>
<th>Explanation for interpreting level of evidence</th>
</tr>
</thead>
<tbody>
<tr>
<td width="168">
<p>High</p>
</td>
<td width="471">
<p>Confident that the true effect in the target population is close to the estimate of the effect observed from the participants included in prior research.</p>
</td>
</tr>
<tr>
<td width="168">
<p>Moderate</p>
</td>
<td width="471">
<p>There is a possibility that the true effect in the target population is substantially different from the estimate of the effect observed from the participants included in prior research</p>
</td>
</tr>
<tr>
<td width="168">
<p>Low</p>
</td>
<td width="471">
<p>True effect in the target population may be substantially different from the estimate of the effect observed from the participants included in prior research</p>
</td>
</tr>
<tr>
<td width="168">
<p>Very low</p>
</td>
<td width="471">
<p>The true effect in the target population is likely substantially different from the estimate of the effect observed from the participants included in prior research</p>
</td>
</tr>
</tbody>
</table>
<p style="text-align: center;">&nbsp;</p>
<p>Evidence from a randomized controlled trial (or meta-analysis where the results of multiple randomized controlled trials have been combined using a statistical approach) is automatically assigned a rating of <em><strong>high</strong></em> quality and non-randomized studies automatically assigned a <em><strong>low</strong></em> rating. However, the evidence rating is then <em><strong>modified downward</strong> </em>if there are concerns about:</p>


- The risk of <em><strong>bias</strong></em> associated with the design of the study or studies that provided evidence for that outcome (also termed *study limitations* by GRADE);
- How <em><strong>precise</strong></em> the results of a study are (termed imprecision by GRADE);
- The degree to which results from different similar studies (comparing the same interventions for example) have <em><strong>varied</strong></em> (termed <strong>inconsistency</strong> by GRADE);
- The evidence available not being totally <em><strong>relevant</strong></em> to the research question at hand (termed indirectness by GRADE);
- The completeness of <em><strong>reporting</strong></em> of research (termed publication bias by grade).



It is also possible to <strong><em>upgrade</em></strong> the quality of evidence assigned to an outcome from a non-randomized or observational study. Upgrading evidence quality for an observational study can be considered when a dose-response gradient is present and large effects are identified (i.e. 2-5 fold reductions or increases in risk) (Guyatt et al., 2011).</p>

Your first reading for this week, is to review the GRADE framework: 

<a href="https://www-bmj-com.myaccess.library.utoronto.ca/content/336/7651/995">
:blue_book: Introduction to GRADE: What is “quality of evidence” and why is it important to clinicians?
</a>

</exercise>

<exercise id="2" title="Summary of findings table">

Again, to provide insight into the bigger picture of what I want you to be able to achieve from this course, below is an example of a **Summary of findings table**. A summary of findings table is essentially a way to summarize the results **and** the quality of evidence for the 'O' component of a clinical question that has been structured in the PICO format, <ins>**as well as**</ins>, GRADE ratings for the quality of evidence. A summary of findings table like the one shown below is what you will be expected to produce as part of your final assignment for the course. You will use the information that makes up the summary of findings table, including the effect estimate and the associated *quality* of evidence for the effect that was observed to help you produce and **justify** your recommendation for or against use of the intervention (as well as whether it is a strong or conditional/weak recommendation). Let's take a look at the example summary of findings table below and have a stab at making a recommendation. 

The example is from a Cochrane review that I have recently updated (the update is currently in the editorial process but the old version is published [here](https://www.cochranelibrary.com/cdsr/doi/10.1002/14651858.CD009491.pub2/full#CD009491-sec1-0001)). The review included only RCTs. The table is structured with rows corresponding to the different outcomes that we selected as being important for decision-making regarding the clinical question, is midazolam more effective than placebo during procedural sedation? Then there are some columns in which the effect estimates are reported and, importantly, the GRADE rating for the quality of evidence. You will note that although some outcomes have the phrase "No studies reported on this outcome" in the comments. This is a vital feature for summary of findings table. We have to be explicitly clear when there is no evidence available for an outcome that we considered important enough to pre-specify in our PICO question. 

In this circumstance, none of the studies that compared oral midazolam with placebo for sedation before a procedure reported level of sedation. The other outcomes we deemed important enough to be used to inform our decision-making about whether or not to recommend oral midazolam for pre-procedural sedation, were ratings of anxiety, ratings of pain and rating of difficulty performing procedures. To summarize, there was *low* quality evidence that midazolam reduced anxiety, there was low quality evidence that there was no important difference between midazolam and placebo in regard to the difficulty performing procedures and there was moderate quality evidence that midazolam reduced pain when given before procedures. Based on this summary of findings, we can make a *conditional* recommendation *for* using midazolam before *diagnostic* procedures in older children and adults. It is conditional in that it was based on low to moderate quality evidence for the outcomes we specified as being important to our decision-making and that not all of our outcomes were able to be assessed due to the fact that no studies reported on level of sedation. Another factor in the decision to make this a *conditional* recommendation is that the population in which the studies that reported on these outcomes, although diverse and including both children and adults, was not entirely representative of the target population of ALL procedures where sedation is commonly used. A common feature of the samples that were included in the studies that provided outcome data were that they were all procedures that were not associated with a high degree of pain and required mostly anxiolysis and motion control. As such, this reasoning informed the component of the *conditional* recommendation regarding the population.

<b>
As an exercise, please review the summary of findings table in detail, and ensure you can identify where the information for each of the following components are located and understand them:

1. Reasons for the GRADE quality of evidence rating
1. Information about all elements of the PICO


</b>


<table cols="7" rows="11"><tr><td colspan="7"><p><b><ins>Summary of findings table: Oral midazolam compared to placebo for sedation before procedures</ins></b></p></td></tr><tr><td colspan="7"><p><b>Patient or population: </b>Children requiring sedation before micturating cystourethrograms, and Kirschner wire removal, and adults undergoing endoscopy<br><b>Settings: </b>X-ray department in Turkey, orthopaedic outpatient department in UK, and endoscopy suites in USA and Thailand<br><b>Intervention:</b> oral midazolam<br><b>Comparison: </b>placebo</p></td></tr><tr><th rowspan="3" valign="top"><p>Outcomes</p></th><th colspan="2" valign="top"><p>Illustrative comparative risks* (95% CI)</p></th><th rowspan="3" valign="top"><p>Relative effect<br>(95% CI)</p></th><th rowspan="3" valign="top"><p>No of Participants<br>(studies)</p></th><th rowspan="3" valign="top"><p>Quality of the evidence<br>(GRADE)</p></th><th rowspan="3" valign="top"><p>Comments</p></th></tr><tr><th valign="top"><p>Assumed risk</p></th><th valign="top"><p>Corresponding risk</p></th></tr><tr><th valign="top"><p>Placebo</p></th><th valign="top"><p>Midazolam</p></th></tr><tr><td valign="top"><p><b>Level of sedation on a sedation assessment scale </b></p><p></p></td><td valign="top"><p></p></td><td><p></p></td><td valign="top"><p></p></td><td valign="top"><p></p></td><td valign="top"><p></p></td><td valign="top"><p>No studies reported on this outcome.</p></td></tr><tr><td valign="top"><p><b>Numeric rating of anxiety or number of participants</b> <b>rated as anxious </b></p></td><td valign="top"><p>Mean scores were 2.6 (scale of 0-8), 4.62 (scale 0-10), 4 (scale 0-10) and 53 (on Spielberger's State Anxiety Scale).</p></td><td valign="top"><p>SMD was <b>1 SD lower </b>(1.86 lower to 0.16 lower)</p></td><td valign="top"><p></p></td><td valign="top"><p>436<br>(4)</p></td><td valign="top"><p><b>low</b><sup>1</sup></p><p>&#8853;&#8853;&#8861;&#8861;</p></td><td valign="top"><p></p></td></tr><tr><td valign="top"><p><b>Proportion of incomplete procedures or where there was difficulty performing the procedures </b></p></td><td valign="top"><p></p></td><td valign="top"><p></p></td><td valign="top"><p></p></td><td valign="top"><p>439</p><p>(4 studies)</p></td><td valign="top"><p><b>low</b><sup>1</sup></p><p>&#8853;&#8853;&#8853;&#8861;</p></td><td valign="top"><p>Relative effect was not able to be conducted because there was only one incomplete procedure in the midazolam group in one of the four trials that reported on this outcome.</p></td></tr><tr><td valign="top"><p><b>Discomfort/Pain</b></p><p>(<b>as defined/measured by the authors of the trial)</b></p></td><td valign="top"><p></p></td><td valign="top"><p></p></td><td valign="top"><p></p></td><td valign="top"><p>99</p><p>(1 study)</p></td><td valign="top"><p><b>moderate</b><sup>2</sup></p><p>&#8853;&#8853;&#8853;&#8861;</p></td><td valign="top"><p>Statistically significant reduction in discomfort/pain (mean 2.56 (SD 0.49) in midazolam group; mean 4.62 (SD 1.49) in placebo group; P &lt; 0.005; scores ranged from 0 to 10; higher score indicated more pain).</p></td></tr><tr><td colspan="7"><p>*The basis for the <b>assumed risk</b> is the control group risk across studies or the average risk for pooled data and the control group risk for single studies. The <b>corresponding risk</b> (and its 95% confidence interval) is based on the assumed risk in the comparison group and the <b>relative effect</b> of the intervention (and its 95% CI).<br><b>CI:</b> Confidence interval; <b>RR:</b> Risk ratio; <b>SMD</b>: Standardized mean difference.</p></td></tr><tr><td colspan="7"><p>GRADE Working Group grades of evidence<br><b>High quality:</b> Further research is very unlikely to change our confidence in the estimate of effect.<br><b>Moderate quality:</b> Further research is likely to have an important impact on our confidence in the estimate of effect and may change the estimate.<br><b>Low quality:</b> Further research is very likely to have an important impact on our confidence in the estimate of effect and is likely to change the estimate.<br><b>Very low quality:</b> We are very uncertain about the estimate.</p></td></tr></table></div><h6 readonly="true" class="fixedtext" >Footnotes</h6><div doc_fld_id="f5072" doc_fld_cnt="f5072" ><p><sup>1</sup>Downgraded two levels due to concerns about study limitations and imprecision.</p><p><sup>2</sup>Downgraded one level due to concerns about study limitations.<br></p></div>

<qu>In week 9 we will cover content in more detail around how to make recommendations using the GRADE approach, but I just wanted to give you this early signpost as to where we are headed.</qu>

<b>
The next reading for the weak is again on GRADE. This article provides guidance about how evidence from summary of findings tables can be translated into recommendations for practice.
</b>
<br><br>
<a href="https://www-sciencedirect-com.myaccess.library.utoronto.ca/science/article/pii/S0895435612001382">
:blue_book: GRADE guidelines: 14. Going from evidence to recommendations: the significance and presentation of recommendations
</a>

</exercise>

<exercise id="3" title="Randomized controlled trials">

Now let's focus back in on the specific topic for this week - <ins>randomized controlled trials</ins>.

Selection of a particular design gives a researcher more or less control over these elements, particularly three major concepts:
1.	Control
1.	Randomization
1.	Manipulation.

Randomized controlled trials contain elements of all three of these concepts. 

## Control

Control is achieved in a study by comparing an outcome between one or more groups whilst ensuring that all participants involved in the research receive the same treatment apart from one aspect that only an intervention group or group receives. In a parallel-group randomized controlled trial, the group of participants who  receives the usual care or treatment is typically termed the ‘control’ group and the group of participants who receives the alternative treatment of interest in termed the  ‘intervention’ group. 

The strength and rigor of a quantitative design relates to controlling the effects of any extraneous variables that may cause bias (threats to internal validity, such as selection, history and maturation) and influence the study findings. These variables can be either antecedent or intervening. An antecedent (preceding) variable occurs before the study commences but may affect the outcome variable of interest and influence findings (e.g. age, gender, socio-economic status or pre-existing health status could affect outcomes such as recovery time and ability to integrate healthcare behaviours). Similarly, an intervening (mediating) variable is not part of the study design, but occurs during the course of the study and may influence the outcome variable (e.g. a change in the model of clinical care during a longitudinal study). 

## Randomization 

Randomization (random assignment) to study groups is designed to ensure that groups or participants are similar on the variables of interest, so that differences in the outcome variable can be attributed to the intervention. Efforts should be made to ensure that participants are assigned to either the experimental or control group on a purely random, or chance, basis. Each participant therefore has an equal and known probability of being assigned to any group. If randomization is not possible, the design should simply be described as ‘non-randomized’. 

It is also important to note that the people who are measuring the outcomes of the study should not know how the randomization falls, or who goes into which groups. This is termed ‘allocation concealment’. In a study of the methodological quality of 250 controlled trials, empirical evidence of bias was discovered with larger effect sizes reported in studies that did not adequately report allocation concealment [(Schulz et al. 1995)](https://jamanetwork.com/journals/jama/fullarticle/386770). There are many potential explanations for this finding, with one being that researchers might inadvertently influence participant selection if inadequate methods are used to conceal allocation assignments. As allocation concealment is a known source of bias associated with randomized controlled trials, the CONSORT statement recommends that the methods used to conceal the allocation sequence is always outlined explicitly in studies reporting results of randomized controlled trials [(Schultz et al., 2010)](https://bmcmedicine.biomedcentral.com/articles/10.1186/1741-7015-8-18?report=reader). Randomization assumes that important intervening variables are then equally distributed between the groups. Studies should report how groups actually compared on demographic and clinical characteristics for each group [(Schultz et al., 2010)](https://bmcmedicine.biomedcentral.com/articles/10.1186/1741-7015-8-18?report=reader).
In addition to concealing the allocation sequence from the researchers enrolling patients into trials, efforts should be made to ensure that:

1. The participants enrolled in the study do not know which group they have been assigned (to reduce risk of performance bias);
1. The clinicians delivering care to the participant do not know which group they have been assigned (to reduce risk of performance bias); and
1. The researchers measuring outcomes do not know which group the participants has been assigned (to reduce risk of detection bias).

Employing these safeguards will minimize the influence from those applying the intervention or treatment under investigation or measuring its effects. A crude (and hypothetical) example is a study of a dressing for wound healing. The dressing is being contrasted with another one that is usually used in practice. If the researchers and their assistants, or the nurses working with the patients, know which dressing is being applied to the wound, they may influence the results by perhaps (even unconsciously) cleaning the wound better prior to applying the alternative dressing rather than the typical one. By blinding the dressing type so no-one knows which one is being applied, and then contrasting the results, a true indication of the effectiveness of the dressing can be identified. You will of course be thinking, though, how is it possible to 'blind' someone as to the type of dressing used? And you'd be correct in thinking that in some circumstances, blinding simply cannot be achieved. In a systematic review that investigated the use of blinding in randomized controlled trials published in nursing journals, it was found that only 10% of the sample of 199 RCTs blinded the study participants to the interventions being tested [(Polit & Gillespie., 2011)](https://journals.lww.com/nursingresearchonline/FullText/2011/01000/Deliberate_Ignorance__A_Systematic_Review_of.2.aspx).

Although difficult to achieve in some circumstances, efforts to implement blinding should always be considered in the planning stages of a RCT because by ensuring that no-one knows which patients receive the intervention, and which ones receive the control or ‘placebo’ condition, a more accurate estimation of the effect of the intervention will be obtained.	There are innovative strategies that researchers can use to blind participants/carers/clinicians. In this example, perhaps it could have been arranged that a research assistant who would have not further involvement in the trial would be the person responsible for applying the dressing and then covering it with a standardized wrap that would obscure the type of dressing used from the participants and clinicians. This would of course require additional resources and feasibility is often the deciding factor in how much effort is placed on blinding in clinical trials.

 
</exercise>

<exercise id="4" title="Risk of bias in randomized controlled trials">


## Risk of bias assessment

<br>

A core element of undertaking a GRADE assessment is to determine if there are study limitations or, in other words, a 'risk of bias' associated with the outcome you are interested in. The diagram below covers the types of risks of bias specifically important when undertaking appraisals of the quality of evidence produced from randomized controlled trial designs.  

<img src="/bias.png"/>

Because we covered the important components of risk of bias assessment during week 6 in NUR1027, I'm not going to re-hash them again now. Here's a [link](https://player.vimeo.com/video/354402956) to the video if you want to view it again though. This semester I want to provide you with a more practical toolset, and show you how to use a risk of bias assessment tool. The best resource for you to use to undertake risk of bias assessments for randomized controlled trials is the **Cochrane risk of bias tool**. Please take a moment to read through the advice provided by the Cochrane Collaboration. In one of the following sections, there is a video of the webinar, where I will demonstrate use of this tool. For more detailed information on risk of bias assessments for randomized controlled trials, please consult the full guidance [document](https://drive.google.com/file/d/19R9savfPdCHC8XLz2iiMvL_71lPJERWK/view) or sections 8.3 to 8.7 of the [Cochrane Handbook](https://training-cochrane-org.myaccess.library.utoronto.ca/handbook/current/chapter-08#section-8-3).

<iframe src="https://drive.google.com/file/d/1Q4Fk3HCuBRwIDWTGZa5oH11OdR4Gbhdo/preview" width="100%" height="1050"></iframe>


</exercise>


<exercise id="5" title="Intervention description">

### TIDieR checklist

Making a recommendation for using an intervention in practice is reliant upon there being an accurate description of the intervention's content and delivery available.  This is particularly so for interventions typically used in nursing practice, which are often more 'complex' than a new drug or device. Incomplete or unclear descriptions of non-pharmacological interventions in particular poses a risk for incorrect implementation. In response to this, The Template for Intervention Description and Replication (TIDieR) checklist and guide was developed by an international team of experts, to promote full and accurate description of interventions. Another way we can use the TIDieR checklist, is as a 'guide' to determine if important aspects of the intervention that has been evaluated in a RCT (or any other type of interventional research design) have been reported in sufficient detail for you to recommend for or against their use in practice. 

The checklist is divided into several parts (why, what, who, how, where, when and how much, tailoring, modifications and how well). If an intervention has not been described adequately to enable replication/implementation, then you may choose to modify the strength (strong or weak/conditional) or even the direction (to use or not to use) of the recommendation regarding implementation of the intervention for practice. You can use the TIDieR checklist to justify your decision-making. 

Please take a quick look over the paper below to familiarize yourself with the essential components of intervention descriptions. 

:blue_book: <a href="https://www.bmj.com/content/348/bmj.g1687">Better reporting of interventions: template for intervention description and replication (TIDieR) checklist and guide</a>


</exercise>

<exercise id="6" title="Statistical considerations for RCTs">

### Minimally clinically important difference

As noted previously, randomized controlled trials are designed to determine the differences in the outcome variable that can be attributed to the intervention. It is very possible, if the sample size is large enough, for a randomized controlled trial to find *statistically significant* differences (i.e. a p value <0.05) between an intervention and control group that are **not** clinically important. This is because the larger the sample size, the more precise the estimate of the effect (i.e. the mean difference, RR, OR...) becomes. This is why it is good practice for researchers to **specify** and **justify** what the minimally clinically important difference is between the intervention and control groups.

### Sample size estimation

One very important aspect of evaluating randomized controlled trials is whether or not a sufficient number of participants were recruited to the study. It is good practice for researchers to *estimate* the number of participants required to detect, with a certain degree of confidence, a difference in the outcome between groups. So keep an eye out in papers for this information, which is often reported in statistical analysis sections as a 'power analysis' or 'sample size calculation'. You don't really have to know the specifics about how a sample size can be estimated for a randomized controlled trial. What **is** important, is being able to determine if the **effect estimate**, so that could be a mean difference, risk taro, absolute risk difference, odds ratio, is **clinically important**. The minimally clinically important difference should be used to estimate the sample size required for the trial.

</exercise>


<exercise id="7" title="Cluster randomization">

There are some specific additional considerations needed when considering evidence from a randomized trial that uses *groups* of people (i.e. 'clusters') as the unit for randomization. The most important being that the 'clustered' nature of the design has to be taken into consideration in the analysis. This is because observations on participants in the same cluster tend to be more similar to each other than to participants from other clusters [(Campbell et al., 2012)](https://www.bmj.com/content/345/bmj.e5661). There are numerous ways to account for clustering in statistical analyses. Knowing whether a particular approach is or is not the most appropriate to use for a specific study is not essential knowledge for you. Being able to identify in a paper that the clustering was accounted for is important. In all cases, accounting for clustering will require use of the 'intra-cluster correlation coefficient'. This is the proportion of the total variance of the outcome that can be explained by the variation between the clusters [(Eldridge et at., 2009)](https://onlinelibrary.wiley.com/doi/full/10.1111/j.1751-5823.2009.00092.x). 

<qu>
When considering evidence from a cluster randomized controlled trial to create a recommendation, you should check to see the intracluster correlation coefficient for the outcome was provided along with result for each outcome. The higher the ICC, the more similar the outcomes were within clusters compared to other clusters. A 'low' ICC would be around 0.01-0.05.
</qu>

</exercise>

<exercise id="8" title="Webinar demo of risk of bias assessment">

A link to the article we will undertake a risk of bias assessment is below:

:link:  <a href="https://academic-oup-com.myaccess.library.utoronto.ca/intqhc/advance-article/doi/10.1093/intqhc/mzz007/5369676">A cluster randomized controlled feasibility study of nurse-initiated behavioural strategies to manage interruptions during medication administration</a>

:file_folder: **A copy of the excel spreadsheet that will be used in the webinar to undertake risk of bias assessments for randomized controlled trials can be downloaded <a href="https://drive.google.com/open?id=1KSFASeBJP8FjBMpEbNlDiYxp4CKuOZgM">here</a>**

<iframe src="https://ca-lti.bbcollab.com/recording/3387e4dbe92748cab512c69e744cb59c" width="100%" height="480" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>

</exercise>

<exercise id="9" title="Readings">

## Required

Gray, J.R., Grove, S.K. & Sutherland, S.  (2017). The Practice of Nursing Research (8th ed.) Chapter 11: Quantitative Methodology: Interventional Designs and Methods. (pp. 217-250).

Lancaster, G.A. & Titman, A.C. (2012). Using evidence from quantitative studies. In J.V. Craig & R.L. Smyth (Eds.) The Evidence-based Practice Manual for Nurses (3rd ed.) (145 – 186).



</exercise>

